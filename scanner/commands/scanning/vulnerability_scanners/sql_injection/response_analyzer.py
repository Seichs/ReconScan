"""
ReconScan SQL Injection Response Analyzer

Advanced response analysis engine for detecting SQL injection vulnerabilities.
Analyzes HTTP responses for vulnerability indicators using multiple detection techniques.
"""

import re
import time
import statistics
from enum import Enum
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple, Any
import hashlib
import difflib

class DetectionTechnique(Enum):
    """SQL injection detection techniques."""
    BOOLEAN_BLIND = "boolean_blind"
    ERROR_BASED = "error_based"
    TIME_BASED = "time_based"
    UNION_BASED = "union_based"
    STACKED_QUERIES = "stacked_queries"

class DatabaseType(Enum):
    """Supported database types for fingerprinting."""
    MYSQL = "mysql"
    POSTGRESQL = "postgresql"
    MSSQL = "mssql"
    ORACLE = "oracle"
    SQLITE = "sqlite"
    UNKNOWN = "unknown"

@dataclass
class ResponseMetrics:
    """Metrics extracted from HTTP response."""
    status_code: int
    content_length: int
    response_time: float
    headers: Dict[str, str]
    content_hash: str
    word_count: int
    error_detected: bool
    database_errors: List[str]

@dataclass
class DetectionResult:
    """Result of vulnerability detection analysis."""
    vulnerable: bool
    technique: DetectionTechnique
    confidence: float
    database_type: Optional[DatabaseType]
    evidence: List[str]
    payload_used: str
    response_metrics: ResponseMetrics
    validation_data: Dict[str, Any]

class SQLInjectionResponseAnalyzer:
    """Advanced response analyzer for SQL injection detection."""
    
    def __init__(self):
        """Initialize the response analyzer with detection patterns."""
        self.baseline_responses = {}
        self.timing_baseline = {}
        self.response_cache = {}
        
        # Database-specific error patterns
        self.error_patterns = {
            DatabaseType.MYSQL: [
                r"You have an error in your SQL syntax",
                r"mysql_fetch_array\(\)",
                r"mysql_fetch_assoc\(\)",
                r"mysql_num_rows\(\)",
                r"Warning.*mysql_.*",
                r"valid MySQL result",
                r"MySQLSyntaxErrorException",
                r"com\.mysql\.jdbc",
                r"Column count doesn't match",
                r"mysql_connect\(\)",
                r"Table.*doesn't exist",
                r"Unknown column",
                r"Duplicate entry.*for key"
            ],
            DatabaseType.POSTGRESQL: [
                r"PostgreSQL.*ERROR",
                r"Warning.*pg_.*",
                r"valid PostgreSQL result",
                r"Npgsql\.",
                r"PG::SyntaxError",
                r"org\.postgresql\.util\.PSQLException",
                r"ERROR:\s*syntax error at or near",
                r"ERROR:\s*relation.*does not exist",
                r"ERROR:\s*column.*does not exist"
            ],
            DatabaseType.MSSQL: [
                r"Driver.*SQL[\-\_\ ]*Server",
                r"OLE DB.*SQL Server",
                r"(\W|\A)SQL Server.*Driver",
                r"Warning.*mssql_.*",
                r"(\W|\A)SQL Server.*[0-9a-fA-F]{8}",
                r"(?s)Exception.*\WSystem\.Data\.SqlClient\.",
                r"(?s)Exception.*\WRoadhouse\.Cms\.",
                r"Microsoft SQL Native Client error '[0-9a-fA-F]{8}",
                r"SQLSTATE \[HY000\] \[Microsoft\]",
                r"Unclosed quotation mark after the character string",
                r"'80040e14'",
                r"mssql_query\(\)",
                r"Microsoft OLE DB Provider for ODBC Drivers.*error",
                r"Invalid column name",
                r"Incorrect syntax near"
            ],
            DatabaseType.ORACLE: [
                r"(\W|\A)ORA-[0-9]{1,4}",
                r"Oracle error",
                r"Oracle.*Driver",
                r"Warning.*\Woci_.*",
                r"Warning.*\Wora_.*",
                r"oracle\.jdbc\.driver",
                r"quoted string not properly terminated"
            ],
            DatabaseType.SQLITE: [
                r"SQLite/JDBCDriver",
                r"SQLite.Exception",
                r"System.Data.SQLite.SQLiteException",
                r"Warning.*sqlite_.*",
                r"Warning.*SQLite3::",
                r"\[SQLITE_ERROR\]",
                r"sqlite3.OperationalError:",
                r"SQLite error \d+:",
                r"sqlite3.DatabaseError:",
                r"no such table:",
                r"near \".*\": syntax error"
            ]
        }
        
        # Generic SQL error patterns
        self.generic_sql_patterns = [
            r"SQL syntax.*MySQL",
            r"Warning.*mysql_.*",
            r"valid MySQL result",
            r"ORA-\d{5}",
            r"Microsoft.*ODBC.*SQL Server.*Driver",
            r"PostgreSQL.*ERROR",
            r"Warning.*\Wpg_.*",
            r"valid PostgreSQL result",
            r"Microsoft.*JET.*Database.*Engine",
            r"Access.*Driver",
            r"\[SQL Server\]",
            r"\[Microsoft\]\[ODBC SQL Server Driver\]",
            r"\[SQLServer JDBC Driver\]",
            r"\[SqlException",
            r"System\.Data\.SqlClient\.SqlException",
            r"Unclosed quotation mark after the character string",
            r"'80040e14'",
            r"mssql_query\(\)",
            r"Microsoft OLE DB Provider for ODBC Drivers",
            r"Microsoft OLE DB Provider for SQL Server",
            r"Incorrect syntax near",
            r"Syntax error in string in query expression",
            r"Data type mismatch in criteria expression",
            r"ADODB\.Field \(0x800A0BCD\)",
            r"BOF or EOF",
            r"ADODB\.Recordset",
            r"Syntax error.*query expression"
        ]
        
        # Boolean-based detection patterns
        self.boolean_indicators = {
            'true_patterns': [
                r'login successful',
                r'welcome',
                r'dashboard',
                r'profile',
                r'admin panel',
                r'user found',
                r'valid',
                r'success'
            ],
            'false_patterns': [
                r'login failed',
                r'invalid',
                r'access denied',
                r'unauthorized',
                r'not found',
                r'error',
                r'failed'
            ]
        }
        
        # Time-based detection settings
        self.time_threshold = 3.0  # seconds
        self.time_tolerance = 0.5  # seconds
        self.baseline_measurements = 3
        
    def establish_baseline(self, normal_response: str, normal_timing: float, 
                          headers: Dict[str, str], status_code: int) -> None:
        """Establish baseline response for comparison."""
        baseline_key = hashlib.md5(normal_response.encode()).hexdigest()[:8]
        
        self.baseline_responses[baseline_key] = {
            'content': normal_response,
            'timing': normal_timing,
            'headers': headers,
            'status_code': status_code,
            'content_length': len(normal_response),
            'word_count': len(normal_response.split()),
            'content_hash': hashlib.md5(normal_response.encode()).hexdigest()
        }
        
    def analyze_response(self, response_content: str, response_time: float,
                        headers: Dict[str, str], status_code: int,
                        payload: str, technique: DetectionTechnique,
                        baseline_key: Optional[str] = None) -> DetectionResult:
        """Analyze response for SQL injection indicators."""
        
        # Create response metrics
        metrics = ResponseMetrics(
            status_code=status_code,
            content_length=len(response_content),
            response_time=response_time,
            headers=headers,
            content_hash=hashlib.md5(response_content.encode()).hexdigest(),
            word_count=len(response_content.split()),
            error_detected=False,
            database_errors=[]
        )
        
        # Perform technique-specific analysis
        if technique == DetectionTechnique.ERROR_BASED:
            return self._analyze_error_based(response_content, metrics, payload)
        elif technique == DetectionTechnique.BOOLEAN_BLIND:
            return self._analyze_boolean_blind(response_content, metrics, payload, baseline_key)
        elif technique == DetectionTechnique.TIME_BASED:
            return self._analyze_time_based(response_content, metrics, payload, baseline_key)
        elif technique == DetectionTechnique.UNION_BASED:
            return self._analyze_union_based(response_content, metrics, payload)
        elif technique == DetectionTechnique.STACKED_QUERIES:
            return self._analyze_stacked_queries(response_content, metrics, payload)
        else:
            return self._generic_analysis(response_content, metrics, payload, technique)
    
    def _analyze_error_based(self, content: str, metrics: ResponseMetrics, 
                           payload: str) -> DetectionResult:
        """Analyze response for error-based SQL injection."""
        database_type = DatabaseType.UNKNOWN
        evidence = []
        confidence = 0.0
        
        # Check for database-specific errors
        for db_type, patterns in self.error_patterns.items():
            for pattern in patterns:
                matches = re.findall(pattern, content, re.IGNORECASE | re.DOTALL)
                if matches:
                    database_type = db_type
                    evidence.extend([f"Database error: {match}" for match in matches])
                    confidence += 0.2
                    metrics.error_detected = True
                    metrics.database_errors.extend(matches)
        
        # Check for generic SQL errors
        for pattern in self.generic_sql_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE | re.DOTALL)
            if matches:
                evidence.extend([f"SQL error: {match}" for match in matches])
                confidence += 0.15
                metrics.error_detected = True
                metrics.database_errors.extend(matches)
        
        # Check for common error indicators
        error_keywords = ['error', 'exception', 'warning', 'fatal', 'syntax', 'unexpected']
        for keyword in error_keywords:
            if keyword.lower() in content.lower() and any(sql_word in content.lower() 
                                                        for sql_word in ['sql', 'database', 'mysql', 'select', 'from']):
                evidence.append(f"Error keyword with SQL context: {keyword}")
                confidence += 0.1
        
        # Cap confidence at 1.0
        confidence = min(confidence, 1.0)
        
        # Determine if vulnerable
        vulnerable = confidence >= 0.3 and len(evidence) > 0
        
        return DetectionResult(
            vulnerable=vulnerable,
            technique=DetectionTechnique.ERROR_BASED,
            confidence=confidence,
            database_type=database_type if database_type != DatabaseType.UNKNOWN else None,
            evidence=evidence,
            payload_used=payload,
            response_metrics=metrics,
            validation_data={'error_count': len(evidence)}
        )
    
    def _analyze_boolean_blind(self, content: str, metrics: ResponseMetrics,
                             payload: str, baseline_key: Optional[str]) -> DetectionResult:
        """Analyze response for boolean-based blind SQL injection."""
        evidence = []
        confidence = 0.0
        
        if not baseline_key or baseline_key not in self.baseline_responses:
            # Without baseline, use content-based heuristics
            return self._heuristic_boolean_analysis(content, metrics, payload)
        
        baseline = self.baseline_responses[baseline_key]
        
        # Compare response characteristics
        content_diff = len(content) - baseline['content_length']
        timing_diff = abs(metrics.response_time - baseline['timing'])
        
        # Content length comparison
        if abs(content_diff) > 50:  # Significant content difference
            evidence.append(f"Content length difference: {content_diff} bytes")
            confidence += 0.3
        
        # Word count comparison
        word_diff = metrics.word_count - baseline['word_count']
        if abs(word_diff) > 10:
            evidence.append(f"Word count difference: {word_diff} words")
            confidence += 0.2
        
        # Content similarity comparison
        similarity = difflib.SequenceMatcher(None, content, baseline['content']).ratio()
        if similarity < 0.8:  # Less than 80% similar
            evidence.append(f"Content similarity: {similarity:.2f}")
            confidence += 0.25
        
        # Status code comparison
        if metrics.status_code != baseline['status_code']:
            evidence.append(f"Status code changed: {baseline['status_code']} -> {metrics.status_code}")
            confidence += 0.2
        
        # Check for boolean-specific patterns
        true_indicators = sum(1 for pattern in self.boolean_indicators['true_patterns']
                            if re.search(pattern, content, re.IGNORECASE))
        false_indicators = sum(1 for pattern in self.boolean_indicators['false_patterns']
                             if re.search(pattern, content, re.IGNORECASE))
        
        if true_indicators > 0:
            evidence.append(f"True condition indicators found: {true_indicators}")
            confidence += 0.3
        elif false_indicators > 0:
            evidence.append(f"False condition indicators found: {false_indicators}")
            confidence += 0.3
        
        confidence = min(confidence, 1.0)
        vulnerable = confidence >= 0.4 and len(evidence) > 0
        
        return DetectionResult(
            vulnerable=vulnerable,
            technique=DetectionTechnique.BOOLEAN_BLIND,
            confidence=confidence,
            database_type=None,
            evidence=evidence,
            payload_used=payload,
            response_metrics=metrics,
            validation_data={
                'content_diff': content_diff,
                'timing_diff': timing_diff,
                'similarity': similarity,
                'true_indicators': true_indicators,
                'false_indicators': false_indicators
            }
        )
    
    def _analyze_time_based(self, content: str, metrics: ResponseMetrics,
                          payload: str, baseline_key: Optional[str]) -> DetectionResult:
        """Analyze response for time-based blind SQL injection."""
        evidence = []
        confidence = 0.0
        
        # Check if response took longer than threshold
        if metrics.response_time >= self.time_threshold:
            evidence.append(f"Response time: {metrics.response_time:.2f}s (threshold: {self.time_threshold}s)")
            
            # Calculate confidence based on delay
            if metrics.response_time >= self.time_threshold * 2:
                confidence = 0.9
            elif metrics.response_time >= self.time_threshold * 1.5:
                confidence = 0.7
            else:
                confidence = 0.5
            
            # If we have baseline timing, compare
            if baseline_key and baseline_key in self.baseline_responses:
                baseline_timing = self.baseline_responses[baseline_key]['timing']
                timing_increase = metrics.response_time - baseline_timing
                
                if timing_increase >= self.time_threshold:
                    evidence.append(f"Timing increase: +{timing_increase:.2f}s from baseline")
                    confidence += 0.2
            
            # Check for time-based payload indicators in content
            time_functions = ['sleep', 'delay', 'waitfor', 'benchmark', 'pg_sleep']
            for func in time_functions:
                if func.lower() in payload.lower():
                    evidence.append(f"Time-based function used: {func}")
                    confidence += 0.1
                    break
        
        confidence = min(confidence, 1.0)
        vulnerable = confidence >= 0.5 and metrics.response_time >= self.time_threshold
        
        return DetectionResult(
            vulnerable=vulnerable,
            technique=DetectionTechnique.TIME_BASED,
            confidence=confidence,
            database_type=None,
            evidence=evidence,
            payload_used=payload,
            response_metrics=metrics,
            validation_data={
                'delay_seconds': metrics.response_time,
                'threshold': self.time_threshold
            }
        )
    
    def _analyze_union_based(self, content: str, metrics: ResponseMetrics,
                           payload: str) -> DetectionResult:
        """Analyze response for UNION-based SQL injection."""
        evidence = []
        confidence = 0.0
        
        # Check for UNION-specific indicators
        union_indicators = [
            r'union.*select',
            r'order\s+by\s+\d+',
            r'group\s+by\s+\d+',
            r'having\s+\d+',
            r'null.*null.*null'
        ]
        
        for pattern in union_indicators:
            if re.search(pattern, content, re.IGNORECASE):
                evidence.append(f"UNION indicator found: {pattern}")
                confidence += 0.2
        
        # Check for data extraction patterns
        data_patterns = [
            r'@@version',
            r'@@database',
            r'user\(\)',
            r'database\(\)',
            r'version\(\)',
            r'current_user',
            r'system_user'
        ]
        
        for pattern in data_patterns:
            if re.search(pattern, content, re.IGNORECASE):
                evidence.append(f"Data extraction pattern: {pattern}")
                confidence += 0.3
        
        # Check for column enumeration
        if 'unknown column' in content.lower() or 'invalid column' in content.lower():
            evidence.append("Column enumeration detected")
            confidence += 0.2
        
        # Check for successful UNION injection indicators
        union_success_patterns = [
            r'\d+\|\d+\|\d+',  # Typical UNION output format
            r'information_schema',
            r'table_name',
            r'column_name',
            r'schema_name'
        ]
        
        for pattern in union_success_patterns:
            if re.search(pattern, content, re.IGNORECASE):
                evidence.append(f"UNION success indicator: {pattern}")
                confidence += 0.4
        
        confidence = min(confidence, 1.0)
        vulnerable = confidence >= 0.3 and len(evidence) > 0
        
        return DetectionResult(
            vulnerable=vulnerable,
            technique=DetectionTechnique.UNION_BASED,
            confidence=confidence,
            database_type=None,
            evidence=evidence,
            payload_used=payload,
            response_metrics=metrics,
            validation_data={'union_indicators': len(evidence)}
        )
    
    def _analyze_stacked_queries(self, content: str, metrics: ResponseMetrics,
                               payload: str) -> DetectionResult:
        """Analyze response for stacked query SQL injection."""
        evidence = []
        confidence = 0.0
        
        # Check for stacked query indicators
        if ';' in payload and any(keyword in payload.lower() 
                                for keyword in ['insert', 'update', 'delete', 'create', 'drop']):
            evidence.append("Stacked query payload detected")
            confidence += 0.3
        
        # Check for multiple statement execution indicators
        multi_statement_patterns = [
            r'Query executed successfully',
            r'rows affected',
            r'Statement executed',
            r'\d+ row\(s\) affected'
        ]
        
        for pattern in multi_statement_patterns:
            if re.search(pattern, content, re.IGNORECASE):
                evidence.append(f"Multi-statement execution: {pattern}")
                confidence += 0.4
        
        # Check for database modification indicators
        modification_indicators = [
            'table created',
            'table dropped',
            'record inserted',
            'record updated',
            'record deleted'
        ]
        
        for indicator in modification_indicators:
            if indicator.lower() in content.lower():
                evidence.append(f"Database modification: {indicator}")
                confidence += 0.5
        
        confidence = min(confidence, 1.0)
        vulnerable = confidence >= 0.3 and len(evidence) > 0
        
        return DetectionResult(
            vulnerable=vulnerable,
            technique=DetectionTechnique.STACKED_QUERIES,
            confidence=confidence,
            database_type=None,
            evidence=evidence,
            payload_used=payload,
            response_metrics=metrics,
            validation_data={'modification_detected': len(evidence) > 0}
        )
    
    def _heuristic_boolean_analysis(self, content: str, metrics: ResponseMetrics,
                                  payload: str) -> DetectionResult:
        """Perform boolean analysis without baseline using heuristics."""
        evidence = []
        confidence = 0.0
        
        # Check for obvious boolean indicators
        if 'true' in content.lower() and 'false' not in content.lower():
            evidence.append("Boolean true indicator found")
            confidence += 0.4
        elif 'false' in content.lower() and 'true' not in content.lower():
            evidence.append("Boolean false indicator found")
            confidence += 0.4
        
        # Check for conditional logic indicators
        conditional_patterns = [
            r'if\s*\(',
            r'case\s+when',
            r'iif\s*\(',
            r'decode\s*\('
        ]
        
        for pattern in conditional_patterns:
            if re.search(pattern, payload, re.IGNORECASE):
                evidence.append(f"Conditional logic in payload: {pattern}")
                confidence += 0.2
        
        # Check for comparison operators in payload
        if any(op in payload for op in ['=', '>', '<', '!=', '<>', 'LIKE']):
            evidence.append("Comparison operators in payload")
            confidence += 0.1
        
        confidence = min(confidence, 1.0)
        vulnerable = confidence >= 0.3 and len(evidence) > 0
        
        return DetectionResult(
            vulnerable=vulnerable,
            technique=DetectionTechnique.BOOLEAN_BLIND,
            confidence=confidence,
            database_type=None,
            evidence=evidence,
            payload_used=payload,
            response_metrics=metrics,
            validation_data={'heuristic_analysis': True}
        )
    
    def _generic_analysis(self, content: str, metrics: ResponseMetrics,
                         payload: str, technique: DetectionTechnique) -> DetectionResult:
        """Generic analysis for unspecified techniques."""
        evidence = []
        confidence = 0.0
        
        # Check for any SQL-related indicators
        sql_indicators = ['select', 'from', 'where', 'union', 'insert', 'update', 'delete']
        for indicator in sql_indicators:
            if indicator.lower() in content.lower():
                evidence.append(f"SQL keyword found: {indicator}")
                confidence += 0.1
        
        # Check for database names or functions
        db_functions = ['database()', 'version()', 'user()', 'current_user', '@@version']
        for func in db_functions:
            if func.lower() in content.lower():
                evidence.append(f"Database function: {func}")
                confidence += 0.2
        
        confidence = min(confidence, 1.0)
        vulnerable = confidence >= 0.3 and len(evidence) > 0
        
        return DetectionResult(
            vulnerable=vulnerable,
            technique=technique,
            confidence=confidence,
            database_type=None,
            evidence=evidence,
            payload_used=payload,
            response_metrics=metrics,
            validation_data={'generic_analysis': True}
        )
    
    def fingerprint_database(self, responses: List[str]) -> DatabaseType:
        """Fingerprint database type based on error patterns."""
        db_scores = {db_type: 0 for db_type in DatabaseType}
        
        for response in responses:
            for db_type, patterns in self.error_patterns.items():
                for pattern in patterns:
                    if re.search(pattern, response, re.IGNORECASE):
                        db_scores[db_type] += 1
        
        # Return database type with highest score
        max_score = max(db_scores.values())
        if max_score > 0:
            for db_type, score in db_scores.items():
                if score == max_score:
                    return db_type
        
        return DatabaseType.UNKNOWN
    
    def validate_vulnerability(self, initial_result: DetectionResult,
                             validation_payloads: List[str],
                             response_getter) -> DetectionResult:
        """Validate vulnerability with additional payloads."""
        if not initial_result.vulnerable:
            return initial_result
        
        validation_results = []
        
        for payload in validation_payloads:
            try:
                response = response_getter(payload)
                result = self.analyze_response(
                    response['content'],
                    response['timing'],
                    response['headers'],
                    response['status_code'],
                    payload,
                    initial_result.technique
                )
                validation_results.append(result)
            except Exception:
                continue
        
        # Calculate validation confidence
        vulnerable_count = sum(1 for r in validation_results if r.vulnerable)
        validation_confidence = vulnerable_count / len(validation_results) if validation_results else 0
        
        # Update confidence based on validation
        updated_confidence = (initial_result.confidence + validation_confidence) / 2
        
        # Require majority of validation tests to pass
        validated_vulnerable = validation_confidence >= 0.5 and initial_result.vulnerable
        
        # Combine evidence
        all_evidence = initial_result.evidence.copy()
        for result in validation_results:
            if result.vulnerable:
                all_evidence.extend(result.evidence)
        
        return DetectionResult(
            vulnerable=validated_vulnerable,
            technique=initial_result.technique,
            confidence=updated_confidence,
            database_type=initial_result.database_type,
            evidence=list(set(all_evidence)),  # Remove duplicates
            payload_used=initial_result.payload_used,
            response_metrics=initial_result.response_metrics,
            validation_data={
                **initial_result.validation_data,
                'validation_count': len(validation_results),
                'validation_confidence': validation_confidence,
                'validation_vulnerable_count': vulnerable_count
            }
        ) 