"""
ReconScan XSS Scanner

Cross-Site Scripting (XSS) vulnerability detection module.
Supports reflected, stored, and DOM-based XSS detection.
"""

import urllib.parse
from ..payloads.xss_payloads import XSSPayloads
from ....ai import AIVulnerabilityValidator

class XSSScanner:
    """XSS vulnerability scanner with pattern-based detection."""
    
    def __init__(self, ai_validator=None):
        """Initialize XSS scanner with AI validation."""
        # Initialize payload library
        self.payload_library = XSSPayloads()
        
        # Get payloads from library (using medium severity by default)
        self.payloads = self.payload_library.get_targeted_payloads('medium')[:15]
        
        # Initialize AI validator
        self.ai_validator = ai_validator or AIVulnerabilityValidator()
        
        # Common parameters for XSS testing
        self.parameters = [
            'q', 'search', 'query', 'name', 'comment', 'message', 'input', 'data',
            'text', 'content', 'value', 'term', 'keyword', 'description', 'title'
        ]
    
    async def scan(self, session, target, verbose=True):
        """Perform XSS vulnerability scan with pattern-based detection."""
        if verbose:
            print("  \033[1;38;5;28m→\033[0m Testing XSS payloads...")
        
        vulnerabilities = []
        vulnerabilities_found = 0
        
        # Use top priority parameters for XSS testing (most likely to be vulnerable)
        priority_params = ['q', 'search', 'query', 'name', 'comment', 'message', 'input', 'data']
        test_params = priority_params + [p for p in self.parameters[:10] if p not in priority_params]
        
        for param in test_params:
            for payload in self.payloads[:8]:  # Test first 8 most effective payloads
                try:
                    # Create test URL with payload
                    test_url = f"{target}?{param}={urllib.parse.quote(payload)}"
                    
                    # Send request
                    async with session.get(test_url) as response:
                        response_body = await response.text()
                        status_code = response.status
                    
                    # Check if payload is reflected in response (basic detection)
                    if payload in response_body:
                        # Use AI validation for comprehensive XSS assessment
                        ai_result = self.ai_validator.validate_xss(
                            test_url, param, payload, response_body, 
                            dict(response.headers), status_code
                        )
                        
                        # If AI determines it's not vulnerable, skip
                        if ai_result.get('is_vulnerable') is False:
                            if verbose:
                                print(f"    \033[1;94mAI\033[0m XSS filtered (confidence: {ai_result.get('confidence', 0):.2f}): {param}={payload[:30]}...")
                                print(f"      Reason: {ai_result.get('reason', 'AI analysis')}")
                            continue
                        
                        vulnerabilities_found += 1
                        vulnerability_info = {
                            'type': 'XSS (Reflected)',
                            'severity': self._determine_severity(payload),
                            'url': test_url,
                            'parameter': param,
                            'payload': payload,
                            'description': f"XSS payload reflected in parameter '{param}'",
                            'evidence': response_body[:200] + "..." if len(response_body) > 200 else response_body,
                            'ai_confidence': ai_result.get('confidence', 0.0),
                            'ai_confidence_level': ai_result.get('confidence_level', 'unknown'),
                            'ai_recommendation': ai_result.get('recommendation', 'Manual verification recommended')
                        }
                        vulnerabilities.append(vulnerability_info)
                        
                        if verbose:
                            print(f"    \033[1;91mX\033[0m XSS found: {param}={payload[:30]}... (AI confidence: {ai_result.get('confidence', 0):.2f})")
                
                except Exception as e:
                    if verbose:
                        print(f"    \033[1;91mWarning\033[0m: Error testing {param}: {str(e)[:50]}...")
                    continue
        
        if verbose:
            print(f"  \033[1;38;5;28m→\033[0m XSS scan completed: {vulnerabilities_found} vulnerabilities found")
        
        return vulnerabilities
    
    def _analyze_response(self, payload, response_body):
        """Simple heuristics to analyze if reflection is likely vulnerable."""
        # Check if payload appears unencoded (likely vulnerable)
        if payload in response_body:
            # Check for HTML encoding (less likely vulnerable)
            import html
            encoded_payload = html.escape(payload)
            if encoded_payload in response_body and payload not in response_body.replace(encoded_payload, ''):
                return False  # Payload is properly encoded
            
            # Check for dangerous contexts
            dangerous_patterns = [
                f'<script>{payload}',
                f'onerror="{payload}"',
                f"onerror='{payload}'",
                f'javascript:{payload}',
                f'<iframe src="{payload}"'
            ]
            
            for pattern in dangerous_patterns:
                if pattern in response_body:
                    return True
            
            # If payload contains script tags and appears unencoded, likely vulnerable
            if '<script>' in payload.lower() and payload in response_body:
                return True
        
        return False
    
    def _determine_severity(self, payload):
        """Determine vulnerability severity based on payload type."""
        payload_lower = payload.lower()
        
        if any(dangerous in payload_lower for dangerous in ['<script>', 'javascript:', 'onerror=']):
            return "High"
        elif any(medium in payload_lower for medium in ['alert(', 'prompt(', 'confirm(']):
            return "Medium"
        else:
            return "Low" 