"""
ReconScan Command Injection Scanner

Command injection vulnerability detection module.
Supports output-based and time-based blind detection methods.
"""

import urllib.parse
import time
from ..payloads.command_injection_payloads import CommandInjectionPayloads
from ....ai import AIVulnerabilityValidator

class CommandInjectionScanner:
    """Command injection vulnerability scanner with blind detection capabilities."""
    
    def __init__(self, ai_validator=None):
        """Initialize command injection scanner with AI validation."""
        # Initialize payload library
        self.payload_library = CommandInjectionPayloads()
        
        # Get payloads from library (using medium severity by default)
        self.payloads = self.payload_library.get_targeted_payloads('medium')
        
        # Get success indicators from library
        self.cmd_indicators = self.payload_library.get_success_indicators()
        
        # Time-based detection threshold (seconds)
        self.time_delay_threshold = 3  # Default 3 seconds for command injection
        
        # Initialize AI validator
        self.ai_validator = ai_validator or AIVulnerabilityValidator()
    
    async def scan(self, session, target, verbose=True):
        """Perform command injection vulnerability scan with blind detection."""
        if verbose:
            print("  \033[1;38;5;28mâ†’\033[0m Testing command injection payloads...")
        
        vulnerabilities = []
        vulnerabilities_found = 0
        
        # Common parameter names for command injection testing
        common_params = self.payload_library.get_common_parameters()[:10]  # Test first 10 common params
        
        # Test output-based detection first
        for param in common_params:
            for payload in self.payloads[:5]:  # Test first 5 payloads per parameter
                try:
                    test_url = f"{target}?{param}={urllib.parse.quote(payload)}"
                    
                    # Measure response time for blind detection
                    start_time = time.time()
                    
                    async with session.get(test_url) as response:
                        content = await response.text()
                        response_time = time.time() - start_time
                        
                        # Check for output-based command injection
                        if any(indicator in content for indicator in self.cmd_indicators):
                            # Use AI validation for command injection assessment
                            ai_result = self.ai_validator.validate_command_injection(
                                test_url, param, payload, content, 
                                dict(response.headers), response.status, response_time
                            )
                            
                            # If AI determines it's not vulnerable, skip
                            if ai_result.get('is_vulnerable') is False:
                                if verbose:
                                    print(f"    \033[1;94mAI\033[0m Command injection filtered (confidence: {ai_result.get('confidence', 0):.2f}): {param}={payload}")
                                    print(f"      Reason: {ai_result.get('reason', 'AI analysis')}")
                                continue
                            
                            vulnerability = {
                                'type': 'Command Injection (Output-based)',
                                'severity': 'Critical',
                                'url': test_url,
                                'payload': payload,
                                'description': f'Command injection vulnerability detected in parameter "{param}" through command output',
                                'ai_confidence': ai_result.get('confidence', 0.0),
                                'ai_confidence_level': ai_result.get('confidence_level', 'unknown'),
                                'ai_recommendation': ai_result.get('recommendation', 'Manual verification recommended')
                            }
                            vulnerabilities.append(vulnerability)
                            vulnerabilities_found += 1
                            if verbose:
                                print(f"    \033[1;91mX\033[0m Command injection found: {param}={payload} (AI confidence: {ai_result.get('confidence', 0):.2f})")
                            break
                            
                except Exception as e:
                    if verbose:
                        print(f"    \033[1;91mWarning\033[0m: Error testing {param} with '{payload}': {str(e)}")
                    continue
            
            # If found vulnerability in this parameter, skip to next parameter
            if vulnerabilities_found > 0:
                break
        
        # Test time-based blind detection if no output-based found
        if vulnerabilities_found == 0:
            time_based_payloads = self.payload_library.get_time_based_payloads()
            
            for param in common_params[:5]:  # Test fewer params for time-based to avoid slowness
                for payload in time_based_payloads[:3]:  # Test first 3 time-based payloads
                    try:
                        test_url = f"{target}?{param}={urllib.parse.quote(payload)}"
                        
                        # Measure response time
                        start_time = time.time()
                        
                        async with session.get(test_url) as response:
                            await response.text()
                            response_time = time.time() - start_time
                            
                            # Check if response took longer than threshold
                            if response_time >= self.time_delay_threshold:
                                # Verify with second request to reduce false positives
                                verification_start = time.time()
                                async with session.get(test_url) as verify_response:
                                    await verify_response.text()
                                    verification_time = time.time() - verification_start
                                
                                # If both requests show delay, likely vulnerable
                                if verification_time >= self.time_delay_threshold:
                                    # Use AI validation for time-based command injection
                                    ai_result = self.ai_validator.validate_command_injection(
                                        test_url, param, payload, "", 
                                        dict(verify_response.headers), verify_response.status, verification_time
                                    )
                                    
                                    # If AI determines it's not vulnerable, skip
                                    if ai_result.get('is_vulnerable') is False:
                                        if verbose:
                                            print(f"    \033[1;94mAI\033[0m Time-based command injection filtered (confidence: {ai_result.get('confidence', 0):.2f}): {param}={payload}")
                                            print(f"      Reason: {ai_result.get('reason', 'AI analysis')}")
                                        continue
                                    
                                    vulnerability = {
                                        'type': 'Command Injection (Time-based Blind)',
                                        'severity': 'High',
                                        'url': test_url,
                                        'payload': payload,
                                        'description': f'Time-based blind command injection detected in parameter "{param}" (response delay: {response_time:.2f}s)',
                                        'ai_confidence': ai_result.get('confidence', 0.0),
                                        'ai_confidence_level': ai_result.get('confidence_level', 'unknown'),
                                        'ai_recommendation': ai_result.get('recommendation', 'Manual verification recommended')
                                    }
                                    vulnerabilities.append(vulnerability)
                                    vulnerabilities_found += 1
                                    if verbose:
                                        print(f"    \033[1;91mX\033[0m Time-based command injection found: {param}={payload} (delay: {response_time:.2f}s, AI confidence: {ai_result.get('confidence', 0):.2f})")
                                    break
                            
                    except Exception as e:
                        if verbose:
                            print(f"    \033[1;91mWarning\033[0m: Error testing time-based {param} with '{payload}': {str(e)}")
                        continue
                
                # If found vulnerability in this parameter, skip to next parameter
                if vulnerabilities_found > 0:
                    break
        
        if verbose and vulnerabilities_found == 0:
            print("    âœ“ No command injection vulnerabilities detected")
        
        return vulnerabilities 